import shutil
import time
import traceback
import zipfile
import joblib
import pandas as pd 
import wave
import librosa
import threading
import matplotlib.pyplot as plt # type: ignore
import librosa.display
import seaborn as sns # type: ignore
import numpy as np
from flask import Flask, Response, render_template, request, jsonify,send_file, url_for
import os
from sklearn.calibration import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import soundfile as sf
from keras.src.saving import load_model
import tensorflow as tf
from werkzeug.utils import secure_filename, send_from_directory,safe_join
from delete_files import delete
from speech import recognizee
from speech import extract_features
from wave_1 import recognize_from_file , recognize_from_waveform
from pydub import AudioSegment
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input , BatchNormalization
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from keras.callbacks import ModelCheckpoint
from flask_cors import CORS
from tensorflow.keras import regularizers
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
import sys
from tensorflow.keras.optimizers import Adam
import matplotlib
matplotlib.use('Agg')  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ù‚Ø¨Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ pyplot
import matplotlib.pyplot as plt
import sounddevice as sd

ALLOWED_EXTENSIONS = {'wav'}

app = Flask(__name__)
CORS(app) 
app.config['MAX_CONTENT_LENGTH'] = 10000 * 1024 * 1024  # 600MB

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
UPLOAD_FOLDER = "uploads"
EXTRACT_FOLDER = "extracted_data"
RECORDINGS_FOLDER = os.path.join(UPLOAD_FOLDER, 'recordings')
TEST_FOLDER = os.path.join(os.getcwd(), 'test')  # Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RECORDINGS_FOLDER, exist_ok=True)
os.makedirs(EXTRACT_FOLDER, exist_ok=True)
os.makedirs(TEST_FOLDER, exist_ok=True)

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¥Ù„Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['RECORDINGS_FOLDER'] = RECORDINGS_FOLDER
app.config['EXTRACT_FOLDER'] = EXTRACT_FOLDER
app.config['TEST_FOLDER'] = TEST_FOLDER  # âœ… ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± ÙŠÙÙ†ÙØ° Ù‚Ø¨Ù„ Ø£ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ù‡


# Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
training_progress = 0  # Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù…
training_done = False  # Ù‡Ù„ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŸ

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
MODEL_PATH = "C:/Users/Rania/Downloads/model/model.h5"
try:
    model = load_model(MODEL_PATH)
    print("âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ù†Ø¬Ø§Ø­!")
    print("âœ… Ø´ÙƒÙ„ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", model.input_shape)
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
# Ø£Ø¶Ù Ù‡Ø°Ø§ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ù…Ù„Ù app.py Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª
emotions = ["Anger", "Disgust", "Fear", "Happiness", "Neutral", "Sadness", "Surprise"]
emotion_map = {emotion.lower(): idx for idx, emotion in enumerate(emotions)}
# ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø¹ÙˆØ§Ø·Ù
EMOTIONS = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']
EMOTION_MAP = {"a": "Anger", "d": "Disgust", "f": "Fear", "h": "Happiness", "n": "Neutral", "s": "Sadness", "su": "Surprise"}
label_encoder = LabelEncoder()
label_encoder.fit(EMOTIONS)
def extract_emotion_from_filename(filename):
    filename = filename.lower()
    if filename.startswith("su"): return EMOTION_MAP["su"]
    return EMOTION_MAP.get(filename[0], "Unknown")

# ğŸ”¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹ Ø¨ØµÙŠØºØ© ØµØ­ÙŠØ­Ø©
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
def convert_to_wav(input_path, output_path):
    try:
        print(f"ğŸ”„ ØªØ­ÙˆÙŠÙ„ {input_path} Ø¥Ù„Ù‰ WAV...")
        
        # ğŸ“Œ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pydub
        audio = AudioSegment.from_file(input_path)
        
        # ğŸ“Œ Ø¶Ø¨Ø· Ø§Ù„ØµÙˆØª Ø¹Ù„Ù‰ Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆÙ…Ø¹Ø¯Ù„ 22050 Ù‡Ø±ØªØ²
        audio = audio.set_channels(1).set_frame_rate(22050)

        # ğŸ“Œ ØªØµØ¯ÙŠØ± Ø§Ù„Ù…Ù„Ù Ø¨ØµÙŠØºØ© WAV
        audio.export(output_path, format="wav")
        
        print(f"âœ… ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ WAV: {output_path}")
        return output_path

    except Exception as e:
        print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ WAV: {e}")
        return None

@app.route('/')
def home():
    return render_template('home.html')
@app.route("/test")
def test_page():
    return render_template("test.html")
@app.route("/train")
def train_page():
    return render_template("train.html")
@app.route('/uploadvoise')
def uploadvoise():
    return render_template('uploadvoise.html')
@app.route('/fileprede')
def fileprede():
    return render_template('fileprede.html')
@app.route('/upload')
def upload():
    return render_template('upload.html')

@app.route('/main')
def main_page():
    return render_template('main.html')
@app.route('/index')
def index():
    return render_template('index.html')

@app.route('/search')
def search():
    return render_template('search.html')
@app.route('/uploads/<path:filename>')
def uploaded_file(filename):
    try:
        upload_folder = os.path.abspath(app.config['UPLOAD_FOLDER'])
        file_path = os.path.join(upload_folder, filename)

        if not os.path.exists(file_path):
            return "âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!", 404

        return send_file(file_path, as_attachment=True)  # Ø§Ø³ØªØ®Ø¯Ø§Ù… send_file Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† send_from_directory
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„Ù: {e}")
        return "âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù", 500

@app.route('/result', methods=['GET', 'POST'])
def upload_file():
    delete()  # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©

    if request.method == 'POST':
        if 'file' not in request.files:
            return render_template("result.html", name="No file part!")

        f = request.files['file']

        if f.filename == '':
            return render_template("result.html", name="No file selected!")

        if not allowed_file(f.filename):
            return render_template("result.html", name="Invalid file type! Only .wav is allowed.")

        filename = secure_filename(f.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        f.save(file_path)  # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù

        ans = recognizee(file_path)  # ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ `recognize()`

        return render_template("result.html", name="File uploaded successfully!", ans=ans)
    
@app.route('/upload_files', methods=['POST'])
def upload_audio_files():
    if 'files' not in request.files:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙŠ Ù…Ù„ÙØ§Øª"}), 400
    files = request.files.getlist('files')
    saved_files = []
    for file in files:
        if file.filename == '':
            continue
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        saved_files.append(filename)
    return jsonify({"message": "ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­", "files": saved_files})

@app.route('/predict', methods=['POST'])
def predict():
    print("ğŸ”¹ Received request at /predict")
    print("ğŸ”¹ Received files:", request.files)

    if 'files' not in request.files:
        print("âŒ No files uploaded!")
        return jsonify({"error": "No files uploaded!"}), 400

    files = request.files.getlist('files')  # Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
    results = []  # Ù‚Ø§Ø¦Ù…Ø© Ù„ØªØ®Ø²ÙŠÙ† Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„ Ù…Ù„Ù

    for file in files:
        if file.filename == '':
            print("âŒ Empty filename, skipping...")
            continue

        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)
        print(f"âœ… File saved at {file_path}")

        # ğŸ”¹ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø¯Ø§Ù„Ø© recognize Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ø¨Ø§Ø´Ø±Ø©
        predicted_emotion = recognizee(file_path)
        print(f"ğŸ¯ Predicted Emotion for {filename}: {predicted_emotion}")

        # ğŸ”¹ ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø©
        results.append({"filename": filename, "emotion": predicted_emotion})

    if not results:
        return jsonify({"error": "No valid files processed"}), 400

    return jsonify({"results": results})


@app.route("/record", methods=["POST"])
def record_audio():
    """
    Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡ØŒ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø¹Ø§Ø·ÙØ©.
    """
    try:
        if "file" not in request.files:
            return jsonify({"error": "âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØªÙŠ!"}), 400

        # âœ… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
        audio_file = request.files["file"]
        filename = os.path.join(UPLOAD_FOLDER, audio_file.filename)
        audio_file.save(filename)
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ: {filename}")

        # âœ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ WAV Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø¨Ø§Ù„ÙØ¹Ù„
        fixed_path = os.path.join(UPLOAD_FOLDER, "fixed_audio.wav")
        converted_path = convert_to_wav(filename, fixed_path)

        if not converted_path:
            return jsonify({"error": "âŒ ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ WAV!"}), 500

        # âœ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `recognize()`
        print("ğŸ” Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª...")
        predicted_emotion = recognizee(fixed_path)

        if "âŒ" in predicted_emotion:
            return jsonify({"error": predicted_emotion}), 500

        print(f"ğŸ¯ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {predicted_emotion}")

        return jsonify({"emotion": predicted_emotion})

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª: {e}")
        return jsonify({"error": f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª: {str(e)}"}), 500

# âœ… Ø¯Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…ÙŠØ²Ø§Øª
@app.route("/list_subfolders", methods=["POST"])
def list_subfolders():
    data = request.json
    base_path = data.get("data_dir", "").replace("\\", "/")

    if not base_path or not os.path.exists(base_path):
        return jsonify({"error": "âš ï¸ Ø§Ù„Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± ØµØ§Ù„Ø­"}), 400

    # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø¯Ø§Ø®Ù„ `Train`
    subfolders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]
    
    if not subfolders:
        return jsonify({"error": "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª ÙØ±Ø¹ÙŠØ© ØµØ§Ù„Ø­Ø©"}), 400
    
    return jsonify({"subfolders": subfolders, "message": "âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©"}), 200

def extract_dataset(zip_path):
    """ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ØµØ­ÙŠØ­ """
    
    # ğŸ”¥ Ø­Ø°Ù Ø£ÙŠ Ù†Ø³Ø®Ø© Ø³Ø§Ø¨Ù‚Ø© Ù…Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯
    if os.path.exists(EXTRACT_FOLDER):
        print(f"ğŸ—‘ï¸ Ø­Ø°Ù Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {EXTRACT_FOLDER}")
        shutil.rmtree(EXTRACT_FOLDER)

    os.makedirs(EXTRACT_FOLDER, exist_ok=True)

    # âœ… ÙÙƒ Ø¶ØºØ· Ø§Ù„Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ extracted_data
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(EXTRACT_FOLDER)

    print("âœ… ØªÙ… ÙÙƒ Ø§Ù„Ø¶ØºØ· Ø¨Ù†Ø¬Ø§Ø­!")

    # âœ… ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·
    print("ğŸ“‚ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¨Ø¹Ø¯ ÙÙƒ Ø§Ù„Ø¶ØºØ·:", os.listdir(EXTRACT_FOLDER))

    # âœ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµØ­ÙŠØ­ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§
    corrected_path = find_first_valid_folder(EXTRACT_FOLDER)

    if not os.listdir(corrected_path):
        raise ValueError(f"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ {corrected_path} Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª!")

    print(f"ğŸ“‚ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ø¹Ø¯ Ø§Ù„ØªØµØ­ÙŠØ­: {corrected_path}")

    return corrected_path

def find_first_valid_folder(base_path):
    """ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ Ù…Ø¬Ù„Ø¯ Ø¯Ø§Ø®Ù„ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª """
    
    all_items = os.listdir(base_path)
    if not all_items:
        raise ValueError(f"ğŸš¨ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø®Ù„ {base_path}")

    # âœ… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ extracted_data Ù†Ø¹ÙŠØ¯ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø±
    for item in all_items:
        item_path = os.path.join(base_path, item)
        if os.path.isfile(item_path):  
            return base_path.replace("\\", "/")  # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­

    # âœ… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ Ù…Ø¬Ù„Ø¯ Ø¯Ø§Ø®Ù„ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª
    for item in all_items:
        item_path = os.path.join(base_path, item)
        if os.path.isdir(item_path) and os.listdir(item_path):  # Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª
            return item_path.replace("\\", "/")

    raise ValueError("ğŸš¨ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬!")

# âœ… Ø¯Ø§Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù…ÙŠØ²Ø§Øª
def load_data(data_dir, is_test=False):
    emotions = ["Anger", "Disgust", "Fear", "Happiness", "Neutral", "Sadness", "Surprise"]
    emotion_map = {e.lower(): i for i, e in enumerate(emotions)}
    X, y = [], []

    if not os.path.exists(data_dir):
        print(f"âŒ Ø®Ø·Ø£: Ø§Ù„Ù…Ø¬Ù„Ø¯ {data_dir} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return np.array([]), np.array([])

    if is_test:
        for file in os.listdir(data_dir):
            file_path = os.path.join(data_dir, file)
            if file.endswith('.wav'):
                try:
                    features = extract_features(file_path)
                    if features is not None:
                        X.append(features)
                        y.append(None)
                except Exception as e:
                    print(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {file_path}: {e}")
    else:
        for emotion in emotions:
            emotion_path = os.path.join(data_dir, emotion)
            if not os.path.exists(emotion_path):
                print(f"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {emotion_path}")
                continue

            for file in os.listdir(emotion_path):
                file_path = os.path.join(emotion_path, file)
                if file.endswith('.wav'):
                    try:
                        features = extract_features(file_path)
                        if features is not None:
                            X.append(features)
                            y.append(emotion_map[emotion.lower()])
                    except Exception as e:
                        print(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {file_path}: {e}")

    if not X:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø©!")
        return np.array([]), np.array([])

    X = np.array(X)
    X = np.expand_dims(X, axis=-1)
    y = np.array(y)

    return X, y

def noise(data):
    noise_amp = 0.035 * np.random.uniform() * np.amax(data)
    return data + noise_amp * np.random.normal(size=data.shape[0])

def stretch(data, rate=0.8):
    return librosa.effects.time_stretch(data, rate=rate)

def pitch(data, sr, pitch_factor=0.7):
    return librosa.effects.pitch_shift(data, sr=sr, n_steps=pitch_factor)

def extract_features(data, sr):
    result = np.array([])
    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)
    result = np.hstack((result, zcr))
    stft = np.abs(librosa.stft(data))
    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)
    result = np.hstack((result, chroma_stft))
    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)
    result = np.hstack((result, mfcc))
    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)
    result = np.hstack((result, rms))
    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sr).T, axis=0)
    return np.hstack((result, mel))

def get_features(path):
    data, sr = librosa.load(path, duration=2.5, offset=0.6)
    features = []
    
    # Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø£ØµÙ„ÙŠ
    features.append(extract_features(data, sr))
    
    # Ù…Ø¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    noise_data = noise(data)
    features.append(extract_features(noise_data, sr))
    
    # Ù…Ø¹ Ø§Ù„ØªÙ…Ø¯ÙŠØ¯ ÙˆØªØºÙŠÙŠØ± Ø§Ù„Ù†ØºÙ…Ø©
    stretched = stretch(data)
    pitched = pitch(stretched, sr)
    features.append(extract_features(pitched, sr))
    
    return np.array(features)

@app.route('/upload_dataset', methods=['POST'])
def upload_dataset():
    if 'file' not in request.files:
        return jsonify({"error": "âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹!"}), 400

    file = request.files['file']
    if not file.filename.endswith('.zip'):
        return jsonify({"error": "âŒ Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨ØµÙŠØºØ© ZIP!"}), 400

    zip_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)

    try:
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ø³Ø§Ø± ÙˆØ§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø­ÙØ¸
        print(f"ğŸ“¥ ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ: {zip_path}")  
        file.save(zip_path)
        print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!")

        # ÙÙƒ Ø§Ù„Ø¶ØºØ·
        extract_path = extract_dataset(zip_path)

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø§ØªØ¬ ØºÙŠØ± ÙØ§Ø±Øº
        if not os.listdir(extract_path):
            raise ValueError(f"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ {extract_path} Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª!")

        print(f"ğŸ“¤ ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©: {extract_path}")  # âœ… ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø±Ø³Ù„

        return jsonify({"folder_path": extract_path})

    except Exception as e:
        return jsonify({"error": f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ÙÙƒ Ø§Ù„Ø¶ØºØ·: {str(e)}"}), 500

@app.route('/train', methods=['POST'])
def train():
    try:
        data = request.get_json()
        data_dir = data.get('data_dir')
        epochs = data.get('epochs', 50)
        
        if not data_dir or not os.path.exists(data_dir):
            return jsonify({"error": "Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­!"}), 400
        
        X, Y = [], []
        for emotion_dir in os.listdir(data_dir):
            dir_path = os.path.join(data_dir, emotion_dir)
            if not os.path.isdir(dir_path):
                continue
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ù„Ù‰ Ù…Ø¤Ø´Ø± Ø±Ù‚Ù…ÙŠ
            emotion_idx = emotion_map.get(emotion_dir.lower())
            if emotion_idx is None:
                continue  # ØªØ®Ø·Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
            
            for file in os.listdir(dir_path):
                if file.endswith('.wav'):
                    file_path = os.path.join(dir_path, file)
                    features = get_features(file_path)
                    for f in features:
                        X.append(f)
                        Y.append(emotion_idx)
        
        if len(X) == 0:
            return jsonify({"error": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨!"}), 400
        
        # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        encoder = OneHotEncoder()
        Y_encoded = encoder.fit_transform(np.array(Y).reshape(-1, 1)).toarray()
        
        X_train, X_test, y_train, y_test = train_test_split(
            np.array(X), Y_encoded, test_size=0.2, random_state=42
        )
        
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        X_train = np.expand_dims(X_train, axis=2)
        X_test = np.expand_dims(X_test, axis=2)
        

        joblib.dump(scaler, "scaler.pkl")
        joblib.dump(encoder, "encoder.pkl")
        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = Sequential()
        model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(X_train.shape[1], 1)))
        model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))
        model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))
        model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))

        model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))
        model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))
        model.add(Dropout(0.2))

        model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))
        model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))

        model.add(Flatten())

# Ø¥Ø¶Ø§ÙØ© L2 regularization Ù„Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„ÙƒØ«ÙŠÙØ©
        model.add(Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
        model.add(Dropout(0.3))

# Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        model.add(Dense(units=7, activation='softmax'))

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

        
        history = model.fit(
            X_train, y_train,
            validation_data=(X_test, y_test),
            epochs=epochs,
            batch_size=64
        )
        
        return jsonify({
            "accuracy": history.history['accuracy'],
            "val_accuracy": history.history['val_accuracy'],
            "loss": history.history['loss'],
            "val_loss": history.history['val_loss']
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500
@app.route('/progress')
def extract_featuress(data, sr):
    result = np.array([])
    try:
        zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)
        result = np.hstack((result, zcr))

        stft = np.abs(librosa.stft(data))
        chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)
        result = np.hstack((result, chroma_stft))

        mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sr, n_mfcc=40).T, axis=0)
        result = np.hstack((result, mfcc))

        rms = np.mean(librosa.feature.rms(y=data).T, axis=0)
        result = np.hstack((result, rms))

        mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sr, n_mels=108).T, axis=0)
        result = np.hstack((result, mel))

        return result[:162]  # ØªØ¹Ø¯ÙŠÙ„: Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø´ÙƒÙ„ (162ØŒ) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† (162ØŒ 1)

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª: {e}")
        return np.zeros(162)  # ØªØ¹Ø¯ÙŠÙ„: Ø¥Ø±Ø¬Ø§Ø¹ Ù…ØµÙÙˆÙØ© 1D Ø¨Ø§Ù„Ø­Ø¬Ù… 162

def get_featuress(path):
    try:
        data, sr = librosa.load(path, duration=2.5, offset=0.6)
        features = []

        features.append(extract_featuress(data, sr))

        noise_data = noise(data)
        features.append(extract_featuress(noise_data, sr))

        stretched = stretch(data)
        pitched = pitch(stretched, sr)
        features.append(extract_featuress(pitched, sr))

        return np.mean(np.array(features), axis=0)  # ØªØ¹Ø¯ÙŠÙ„: Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„Ù‡ Ø¥Ù„Ù‰ (162ØŒ 1)

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {path}: {e}")
        return np.zeros(162)  # ØªØ¹Ø¯ÙŠÙ„: Ø¥Ø±Ø¬Ø§Ø¹ Ù…ØµÙÙˆÙØ© 1D Ø¨Ø§Ù„Ø­Ø¬Ù… 162
def test_modele(audio_files):
    features_list = [get_featuress(file) for file in audio_files]
    X_test = np.array(features_list)  # Ø§Ù„Ø¢Ù† X_test Ø³ÙŠÙƒÙˆÙ† (num_samples, 162)

    # ØªØ·Ø¨ÙŠÙ‚ StandardScaler
    scaler = StandardScaler()
    X_test = scaler.fit_transform(X_test)  # Ø¶Ø¨Ø· Ø§Ù„Ù‚ÙŠÙ… Ø¶Ù…Ù† Ù†Ø·Ø§Ù‚ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    X_test = np.expand_dims(X_test, axis=-1)  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªØ§Ø¬ Ø¨Ø¹Ø¯Ù‹Ø§ Ø¥Ø¶Ø§ÙÙŠÙ‹Ø§

    # ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¹ÙˆØ§Ø·Ù
    predictions = model.predict(X_test)
    predicted_emotions = [EMOTIONS[np.argmax(pred)] for pred in predictions]

    return predicted_emotions

# ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ù…Ø¹ÙŠÙ†
audio_folder = "C:\\Users\\Rania\\Downloads\\datasat\\Validation"
audio_files = [os.path.join(audio_folder, file) for file in os.listdir(audio_folder) if file.endswith(".wav")]

if audio_files:
    results = test_modele(audio_files)
    for file, emotion in zip(audio_files, results):
        print(f"ğŸµ Ø§Ù„Ù…Ù„Ù: {os.path.basename(file)}  --> ğŸ­ Ø§Ù„Ø¹Ø§Ø·ÙØ© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: {emotion}")
else:
    print("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯!")


@app.route('/test', methods=['GET', 'POST'])
def test_model():
    if request.method == 'GET':
        return render_template('test.html')
    
    elif request.method == 'POST':
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
            if 'test_dataset' not in request.files:
                return jsonify({'status': 'Error', 'message': 'âŒ No test dataset uploaded.'})
            
            test_file = request.files['test_dataset']
            if test_file.filename == '':
                return jsonify({'status': 'Error', 'message': 'âŒ No file selected!'})

            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            filename = secure_filename(test_file.filename)
            filepath = os.path.join(app.config['TEST_FOLDER'], filename)
            test_file.save(filepath)
            print(f"âœ… Test dataset saved at {filepath}.")

            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ZIP
            if not zipfile.is_zipfile(filepath):
                return jsonify({'status': 'Error', 'message': 'âŒ The uploaded file is not a valid ZIP archive.'})

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª
            extract_path = os.path.join(app.config['TEST_FOLDER'], 'test_extracted')
            os.makedirs(extract_path, exist_ok=True)

            with zipfile.ZipFile(filepath, 'r') as zip_ref:
                zip_ref.extractall(extract_path)
            print(f"âœ… Test dataset extracted to {extract_path}.")

            # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„ØªØµÙ†ÙŠÙØ§Øª
            audio_files = []
            labels = []
            for root, _, files in os.walk(extract_path):
                for file in files:
                    if file.endswith(".wav"):
                        audio_files.append(os.path.join(root, file))
                        labels.append(os.path.basename(root))  # Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ù‡Ùˆ Ø§Ù„ØªØµÙ†ÙŠÙ

            if len(audio_files) < 2:
                return jsonify({'status': 'Error', 'message': 'âŒ The test dataset must contain at least 2 classes.'})

            print(f"âœ… Found {len(audio_files)} audio files.")

            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            MODEL_PATH = "C:/Users/Rania/Downloads/model/modelee.h5"
            if not os.path.exists(MODEL_PATH):
                return jsonify({'status': 'Error', 'message': f'âŒ Model not found at: {MODEL_PATH}'})

            model = tf.keras.models.load_model(MODEL_PATH)
            print("âœ… Model loaded successfully.")

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            features_list = [get_featuress(file) for file in audio_files]
            X_test = np.array(features_list)

# **Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© StandardScaler Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯**
            if len(X_test.shape) == 3:  
                X_test = X_test.reshape(X_test.shape[0], -1)  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¨Ø¹Ø¯ÙŠÙ†

            scaler = StandardScaler()
            X_test = scaler.fit_transform(X_test)

# Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            X_test = np.expand_dims(X_test, axis=-1)


            # ØªØ±Ù…ÙŠØ² Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª
            encoder = OneHotEncoder()
            y_test_encoded = encoder.fit_transform(np.array(labels).reshape(-1, 1)).toarray()

            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            evaluation = model.evaluate(X_test, y_test_encoded, verbose=1)
            evaluation_accuracy = evaluation[1] * 100
            print(f"âœ… Model Evaluation Accuracy: {evaluation_accuracy:.2f}%")

            # Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª
            y_pred = np.argmax(model.predict(X_test), axis=1)
            y_true = np.argmax(y_test_encoded, axis=1)

            # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ
            conf_matrix = confusion_matrix(y_true, y_pred)
            report = classification_report(y_true, y_pred, target_names=list(set(labels)), output_dict=True)

            # Ø­ÙØ¸ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ
            conf_matrix_path = os.path.join(app.static_folder, 'test', 'confusion_matrix.png')
            plt.figure(figsize=(8, 6))
            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=list(set(labels)), yticklabels=list(set(labels)))
            plt.xlabel('Predicted')
            plt.ylabel('True')
            plt.title('Confusion Matrix')
            plt.savefig(conf_matrix_path)
            plt.close()

            return jsonify({
                'status': 'Test Completed',
                'accuracy': evaluation_accuracy,
                'confusion_matrix': url_for('static', filename='test/confusion_matrix.png'),
                'classification_report': report
            })

        except Exception as e:
            print("âŒ Error occurred:", traceback.format_exc())
            return jsonify({'status': 'Error', 'message': str(e)})
@app.route('/progress')
def progress():
    def generate():
        for i in range(101):  # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø¯Ù… Ù…Ù† 0 Ø¥Ù„Ù‰ 100
            yield f"data: {{\"progress\": {i}}}\n\n"
            time.sleep(0.1)  # Ù…Ø­Ø§ÙƒØ§Ø© Ø¹Ù…Ù„ÙŠØ© ØªØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹
    return Response(generate(), content_type='text/event-stream')
   
if __name__ == "__main__":
    app.run(debug=True, use_reloader=False)
